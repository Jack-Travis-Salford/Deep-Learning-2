{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read and has shape (20491, 2)\n",
      "                                                  Review  Rating\n",
      "0      nice hotel expensive parking got good deal sta...       4\n",
      "1      ok nothing special charge diamond member hilto...       2\n",
      "2      nice rooms not 4* experience hotel monaco seat...       3\n",
      "3      unique, great stay, wonderful time hotel monac...       5\n",
      "4      great stay great stay, went seahawk game aweso...       5\n",
      "...                                                  ...     ...\n",
      "20486  best kept secret 3rd time staying charm, not 5...       5\n",
      "20487  great location price view hotel great quick pl...       4\n",
      "20488  ok just looks nice modern outside, desk staff ...       2\n",
      "20489  hotel theft ruined vacation hotel opened sept ...       1\n",
      "20490  people talking, ca n't believe excellent ratin...       2\n",
      "\n",
      "[20491 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataFile = pd.read_csv(\"Data File/tripadvisor_hotel_reviews.csv\")\n",
    "\n",
    "#dataFile['Rating'] = dataFile.Rating.astype('category')\n",
    "#print(dataFile.dtypes)\n",
    "\n",
    "print(\"Data read and has shape\", dataFile.shape)\n",
    "print(dataFile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T09:18:56.589749Z",
     "end_time": "2023-05-05T09:18:56.734786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "no_reviews = 20491    # no of reviews that will be read from file.\n",
    "max_review_length = 500 # no of words per review.  reviews will be  truncated or padded to be of this length.\n",
    "max_words = 52212        # this is the size of the index (i.e. most common top words that will be used as features)\n",
    "# note code assumes there are enough words in reviews.\n",
    "embedding_dim = 100     # length of embedding based on Glove\n",
    "validation_prop = 0.2   # prop of data for validation set\n",
    "no_epochs =   20         # No of training cycles for the networks\n",
    "batch_size = 64        # batch size for training\n",
    "\n",
    "training_samples = 12000\n",
    "validation_samples = 7000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T09:18:56.736787Z",
     "end_time": "2023-05-05T09:18:56.767193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "# Use the tokenizer to code the reviews\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "reviews = dataFile[\"Review\"].values\n",
    "ratings = dataFile[\"Rating\"].values\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "dataFile = pad_sequences(sequences, maxlen=max_review_length)\n",
    "#print(f'Found {len(word_index)} unique tokens')\n",
    "\n",
    "labels = to_categorical(np.asarray(ratings-1))\n",
    "x_test = dataFile[19000:]\n",
    "y_test = labels[19000:]\n",
    "testExamples = len(labels)-19000\n",
    "x_train, x_val, y_train, y_val= train_test_split(dataFile[:19000], labels[:19000], test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T09:18:56.750077Z",
     "end_time": "2023-05-05T09:19:00.402549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of words in glove embeddings = 400000\n"
     ]
    }
   ],
   "source": [
    "glove_dir = \".\\\\Glove\\\\glove.6B\"\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open(os.path.join(glove_dir,'glove.6B.100d.txt'),encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('no of words in glove embeddings =', len(embeddings_index))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T09:19:00.404547Z",
     "end_time": "2023-05-05T09:19:11.558942Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of embeddings matrix is: (52212, 100)\n",
      "1:hotel\t--> [ 0.43044001 -0.71715999  0.13989     0.59311002 -0.16727     0.56128001]\n",
      "2:room\t--> [-0.024843    0.47766     0.32437    -0.054239   -0.47622001  1.10430002]\n",
      "3:not\t--> [-0.19103999  0.17601     0.36919999 -0.50322998 -0.47560999  0.15798   ]\n",
      "4:great\t--> [-0.013786    0.38216001  0.53236002  0.15261    -0.29694    -0.20558   ]\n",
      "5:n't\t--> [ 0.15730999  0.3953      0.63586003 -1.09749997 -0.95767999 -0.013841  ]\n",
      "6:good\t--> [-0.030769    0.11993     0.53908998 -0.43696001 -0.73936999 -0.15345   ]\n",
      "7:staff\t--> [-0.61250001 -0.29506999 -0.28917    -0.36431    -0.39695001  0.097624  ]\n",
      "8:stay\t--> [-0.41615999 -0.26538     0.21720999 -0.26014999 -0.18043999  0.38745001]\n",
      "9:did\t--> [ 0.30449    -0.19628     0.20225    -0.61686999 -0.68484002 -0.11887   ]\n",
      "10:just\t--> [ 0.075026    0.39324999  0.90314001 -0.30451    -0.32767999  0.59630001]\n"
     ]
    }
   ],
   "source": [
    "#look for word embeddings\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "\n",
    "for word,i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "print(\"shape of embeddings matrix is:\",  embedding_matrix.shape)\n",
    "\n",
    "# print some entries\n",
    "\n",
    "for word,i in word_index.items():\n",
    "    if i > 10: break\n",
    "    print(f'{i}:{word}\\t--> { embedding_matrix[i, 0:6]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T09:19:11.562944Z",
     "end_time": "2023-05-05T09:19:11.695203Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 500, 100)          5221200   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              84480     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,306,325\n",
      "Trainable params: 85,125\n",
      "Non-trainable params: 5,221,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, LSTM\n",
    "from keras import layers\n",
    "\n",
    "network_G = Sequential()\n",
    "network_G.add(Embedding(len(word_index)+1, embedding_dim, weights=[embedding_matrix], input_length=max_review_length, trainable=False))\n",
    "network_G.add(layers.Bidirectional(LSTM(64)))\n",
    "network_G.add(Dense(5, activation='softmax'))\n",
    "network_G.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T09:19:11.653449Z",
     "end_time": "2023-05-05T09:19:12.157603Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "238/238 [==============================] - 162s 669ms/step - loss: 1.2632 - acc: 0.4626 - val_loss: 1.1937 - val_acc: 0.4882\n",
      "Epoch 2/20\n",
      "238/238 [==============================] - 135s 570ms/step - loss: 1.0663 - acc: 0.5301 - val_loss: 0.9812 - val_acc: 0.5626\n",
      "Epoch 3/20\n",
      "238/238 [==============================] - 138s 580ms/step - loss: 0.9347 - acc: 0.5860 - val_loss: 0.9182 - val_acc: 0.5984\n",
      "Epoch 4/20\n",
      "238/238 [==============================] - 135s 567ms/step - loss: 0.8736 - acc: 0.6165 - val_loss: 0.9118 - val_acc: 0.6068\n",
      "Epoch 5/20\n",
      "238/238 [==============================] - 131s 552ms/step - loss: 0.8401 - acc: 0.6314 - val_loss: 0.8669 - val_acc: 0.6161\n",
      "Epoch 6/20\n",
      "238/238 [==============================] - 131s 549ms/step - loss: 0.8071 - acc: 0.6442 - val_loss: 0.8429 - val_acc: 0.6253\n",
      "Epoch 7/20\n",
      "238/238 [==============================] - 132s 554ms/step - loss: 0.7889 - acc: 0.6535 - val_loss: 0.8422 - val_acc: 0.6321\n",
      "Epoch 8/20\n",
      "238/238 [==============================] - 129s 542ms/step - loss: 0.7697 - acc: 0.6634 - val_loss: 0.8455 - val_acc: 0.6292\n",
      "Epoch 9/20\n",
      "238/238 [==============================] - 130s 545ms/step - loss: 0.7504 - acc: 0.6711 - val_loss: 0.8308 - val_acc: 0.6411\n",
      "Epoch 10/20\n",
      "238/238 [==============================] - 130s 545ms/step - loss: 0.7280 - acc: 0.6804 - val_loss: 0.8282 - val_acc: 0.6366\n",
      "Epoch 11/20\n",
      "238/238 [==============================] - 126s 529ms/step - loss: 0.7062 - acc: 0.6901 - val_loss: 0.8323 - val_acc: 0.6411\n",
      "Epoch 12/20\n",
      "238/238 [==============================] - 126s 530ms/step - loss: 0.6964 - acc: 0.6927 - val_loss: 0.8604 - val_acc: 0.6200\n",
      "Epoch 13/20\n",
      "238/238 [==============================] - 127s 536ms/step - loss: 0.6748 - acc: 0.7037 - val_loss: 0.8619 - val_acc: 0.6334\n",
      "Epoch 14/20\n",
      "238/238 [==============================] - 131s 551ms/step - loss: 0.6547 - acc: 0.7099 - val_loss: 0.8570 - val_acc: 0.6347\n",
      "Epoch 15/20\n",
      "238/238 [==============================] - 133s 558ms/step - loss: 0.6387 - acc: 0.7201 - val_loss: 0.8533 - val_acc: 0.6303\n",
      "Epoch 16/20\n",
      "238/238 [==============================] - 133s 559ms/step - loss: 0.6162 - acc: 0.7324 - val_loss: 0.9497 - val_acc: 0.6266\n",
      "Epoch 17/20\n",
      "238/238 [==============================] - 149s 627ms/step - loss: 0.6001 - acc: 0.7430 - val_loss: 0.8861 - val_acc: 0.6205\n",
      "Epoch 18/20\n",
      "238/238 [==============================] - 149s 627ms/step - loss: 0.5740 - acc: 0.7533 - val_loss: 0.9255 - val_acc: 0.6239\n",
      "Epoch 19/20\n",
      "238/238 [==============================] - 152s 637ms/step - loss: 0.5535 - acc: 0.7617 - val_loss: 0.9193 - val_acc: 0.6179\n",
      "Epoch 20/20\n",
      "238/238 [==============================] - 182s 767ms/step - loss: 0.5360 - acc: 0.7713 - val_loss: 0.9480 - val_acc: 0.6213\n"
     ]
    }
   ],
   "source": [
    "network_G.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'] )\n",
    "\n",
    "hist_g = network_G.fit(x_train,y_train, epochs=no_epochs, batch_size=batch_size, validation_data= (x_val,y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T09:19:12.133370Z",
     "end_time": "2023-05-05T10:05:13.019820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491/1491 [==============================] - 41s 28ms/step - loss: 0.8864 - acc: 0.6392\n",
      "Accuracy on test set: 0.639\n"
     ]
    }
   ],
   "source": [
    "res = network_G.evaluate(x_test, y_test, steps=testExamples, verbose=1)\n",
    "print('Accuracy on test set: %.3f' % res[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T10:05:13.040819Z",
     "end_time": "2023-05-05T10:05:54.528196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T10:05:54.531228Z",
     "end_time": "2023-05-05T10:05:54.568758Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
